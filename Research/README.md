# Решение кейса

В рамках кейса мы решили сравнить 4 модели: `Naive Bayes Classifier + TF-IDF`, `FastText`, `BERT Vectorizer + biGRU` и `BERT Classifier`

## Предобработка текста

Для одинаковой предобработки датасета мы использовали следующий подход:
- Удаляем все цифры
- Удаляем стоп слова и пунктуацию
- Лемматизирует
- Удаляем месяцы и просто буквы

После такой предобработки качество NVB+TF-IDF рассмотренных моделей выросло на ~8 процентных пунктов

## Результаты

|Название модели|Accuracy|F1-Score|
|---|---|---|
|NBC + TF-IDF|0.9125|0.9255|
|FastText| 0.97 | 0.97 |
|biGRU| 0.97 | 0.98 |
|RuBERT| - | - |

## Валидация моделей

Также мы оценили дискриминационные способности моделей и ее стабильность с помощью тестов индексом Джини и критерием Колмогорова-Смирнова

|Название модели|Индекс Джини|p-value критерия Колмогорова-Смирнова|Статистика критерия Колмогорова-Смирнова|
|---|---|---|---|
|NBC + TF-IDF| - | - | - |
|FastText| - | - | - |
|biGRU| 0.9983 | 0.000059 | 0.99 |
|RuBERT| - | - | - |

И с интервальной оценкой ROC-AUC построили распределения:

TODO: вставить фотку
